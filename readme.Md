# Modern Data Warehouse with dbt (Medallion Architecture)

## ğŸ“Œ Project Overview
This project demonstrates a production-grade batch data pipeline using the Medallion Architecture (Bronze, Silver, Gold layers) and **dbt (data build tool)**. It extracts raw e-commerce data, loads it into a cloud data warehouse, and transforms it into business-ready analytical tables.



## ğŸ¯ Objectives
* **Data Modeling:** Implement a scalable Medallion Architecture.
* **Data Quality:** Enforce data integrity using dbt tests (unique, not_null, accepted_values).
* **Version Control:** Maintain data transformations as code (Analytics Engineering).
* **Documentation:** Auto-generate data lineage graphs and data dictionaries.

## ğŸ› ï¸ Tech Stack
* **Data Warehouse:** [Google BigQuery / Snowflake / PostgreSQL]
* **Transformation Engine:** dbt Core
* **Language:** SQL, Python (for initial load)
* **Containerization:** Docker (optional, for running dbt)

## ğŸ“‚ Project Structure

```text
â”œâ”€â”€ data/                      # Raw seed data (CSV)
â”œâ”€â”€ dbt_project/               # Main dbt project folder
â”‚   â”œâ”€â”€ models/                # SQL transformation models
â”‚   â”‚   â”œâ”€â”€ bronze/            # Raw data views (Source)
â”‚   â”‚   â”œâ”€â”€ silver/            # Cleaned, conformed, and deduplicated data
â”‚   â”‚   â””â”€â”€ gold/              # Business-level aggregations and reporting tables
â”‚   â”œâ”€â”€ tests/                 # Custom singular data tests
â”‚   â”œâ”€â”€ macros/                # Reusable SQL functions
â”‚   â”œâ”€â”€ dbt_project.yml        # dbt configuration file
â”‚   â””â”€â”€ packages.yml           # dbt dependencies (e.g., dbt-utils)
â”œâ”€â”€ scripts/                   # Python scripts for data loading
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md
